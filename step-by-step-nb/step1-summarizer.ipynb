{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yhb19\\.conda\\envs\\chatgpt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vnov.story import Summarizer\n",
    "from vnov.llms.poe import Poe\n",
    "from vnov.llms.deepseek import Deepseek\n",
    "from vnov.data import Novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing email dict out of email accounts ['llu430173@gmail.com', 'luke.yangluhb@gmail.com', 'yang_huibo@outlook.com', 'lluke6025@gmail.com', 'lu4431928@gmail.com', 'yhb19991115@gmail.com', 'legolukeluke3@gmail.com']\n",
      "Switching email\n",
      "Switched to new email account llu430173@gmail.com\n"
     ]
    }
   ],
   "source": [
    "model = Poe()\n",
    "# model = Deepseek()\n",
    "novel = Novel( \"datasets/11-0\", \"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing chapter 1...\n",
      "Summarizing chapter 1 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\1_summary_comprehensive.txt\n",
      "Chapter 1 summarized.\n",
      "Summarizing chapter 2...\n",
      "Summarizing chapter 2 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\2_summary_comprehensive.txt\n",
      "Chapter 2 summarized.\n",
      "Summarizing chapter 3...\n",
      "Summarizing chapter 3 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\3_summary_comprehensive.txt\n",
      "Chapter 3 summarized.\n",
      "Summarizing chapter 4...\n",
      "Summarizing chapter 4 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\4_summary_comprehensive.txt\n",
      "Chapter 4 summarized.\n",
      "Summarizing chapter 5...\n",
      "Summarizing chapter 5 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\5_summary_comprehensive.txt\n",
      "Chapter 5 summarized.\n",
      "Summarizing chapter 6...\n",
      "Summarizing chapter 6 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\6_summary_comprehensive.txt\n",
      "Chapter 6 summarized.\n",
      "Summarizing chapter 7...\n",
      "Summarizing chapter 7 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\7_summary_comprehensive.txt\n",
      "Chapter 7 summarized.\n",
      "Summarizing chapter 8...\n",
      "Summarizing chapter 8 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\8_summary_comprehensive.txt\n",
      "Chapter 8 summarized.\n",
      "Summarizing chapter 9...\n",
      "Summarizing chapter 9 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\9_summary_comprehensive.txt\n",
      "Chapter 9 summarized.\n",
      "Summarizing chapter 10...\n",
      "Summarizing chapter 10 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\10_summary_comprehensive.txt\n",
      "Chapter 10 summarized.\n",
      "Summarizing chapter 11...\n",
      "Summarizing chapter 11 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\11_summary_comprehensive.txt\n",
      "Chapter 11 summarized.\n",
      "Summarizing chapter 12...\n",
      "Summarizing chapter 12 with length comprehensive...\n",
      "Saving to datasets/11-0\\default\\summary\\12_summary_comprehensive.txt\n",
      "Chapter 12 summarized.\n",
      "Summarizing chapter 13...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/11-0\\\\original\\\\13.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m Summarizer(model)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msummarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnovel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomprehensive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Academic\\NLP\\vnov\\vnov\\story\\summarizer.py:64\u001b[0m, in \u001b[0;36mSummarizer.summarize\u001b[1;34m(self, novel, save_dir, summary_length, start_chapter, end_chapter, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chapter_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_chapter, end_chapter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizing chapter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m     summary, scene_jsons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize_chapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnovel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchapter_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     last_context \u001b[38;5;241m=\u001b[39m scene_jsons[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scene_jsons \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_file(summary, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_summary_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32md:\\Academic\\NLP\\vnov\\vnov\\story\\summarizer.py:16\u001b[0m, in \u001b[0;36mSummarizer.summarize_chapter\u001b[1;34m(self, novel, chapter_num, summary_length, last_context, new_chat)\u001b[0m\n\u001b[0;32m     14\u001b[0m summaries, scene_jsons \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     15\u001b[0m cur_max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_cur_max_length(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, SUMMARIZER_INSTRUCTION, last_context)\n\u001b[1;32m---> 16\u001b[0m chapter_content \u001b[38;5;241m=\u001b[39m \u001b[43mnovel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_chapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchapter_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# chapter_content, next_content = Novel.trunc_chapter(chapter_content, cur_max_length)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m chapter_content, next_content \u001b[38;5;241m=\u001b[39m chapter_content, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Academic\\NLP\\vnov\\vnov\\data\\data.py:78\u001b[0m, in \u001b[0;36mNovel.load_chapter\u001b[1;34m(self, chapter, mode, extension, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_chapter\u001b[39m(\u001b[38;5;28mself\u001b[39m, chapter: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m NOVEL_MODE\u001b[38;5;241m.\u001b[39mORIGINAL, extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dir(mode)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/11-0\\\\original\\\\13.txt'"
     ]
    }
   ],
   "source": [
    "summarizer = Summarizer(model)\n",
    "summarizer.summarize(novel, summary_length=\"comprehensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
