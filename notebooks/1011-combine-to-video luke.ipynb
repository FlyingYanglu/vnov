{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pil\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.tools.subtitles import SubtitlesClip, TextClip\n",
    "import os\n",
    "import re\n",
    "from moviepy.config import change_settings\n",
    "pil.ANTIALIAS = pil.Resampling.LANCZOS\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI\\\\magick.exe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_srt(srt_file, encoding=\"utf-8\"):\n",
    "    \"\"\"Parses the SRT file into a list of (start_time, end_time, subtitle_text) tuples.\"\"\"\n",
    "    pattern = re.compile(r\"(\\d{2}):(\\d{2}):(\\d{2}),(\\d{3})\")\n",
    "    subtitles = []\n",
    "\n",
    "    with open(srt_file, 'r', encoding=encoding) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current_sub = {}\n",
    "    for line in lines:\n",
    "        # Match time codes\n",
    "        if pattern.search(line):\n",
    "            times = pattern.findall(line)\n",
    "            start_time = int(times[0][0]) * 3600 + int(times[0][1]) * 60 + int(times[0][2]) + int(times[0][3]) / 1000\n",
    "            end_time = int(times[1][0]) * 3600 + int(times[1][1]) * 60 + int(times[1][2]) + int(times[1][3]) / 1000\n",
    "            current_sub['start'] = start_time\n",
    "            current_sub['end'] = end_time\n",
    "        elif line.strip() == '':\n",
    "            if 'text' in current_sub:\n",
    "                # Remove prefix numbers and keep only the subtitle text\n",
    "                text = re.sub(r'^\\d+\\s*', '', current_sub['text'].strip())\n",
    "                subtitles.append((current_sub['start'], current_sub['end'], text))\n",
    "            current_sub = {}\n",
    "        else:\n",
    "            if 'text' not in current_sub:\n",
    "                current_sub['text'] = line.strip()\n",
    "            else:\n",
    "                current_sub['text'] += ' ' + line.strip()\n",
    "    \n",
    "    return subtitles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from moviepy.editor import TextClip\n",
    "\n",
    "def create_video_with_audio_and_subtitles(image_file, audio_file, subtitle_file, output_file, direction=0):\n",
    "\n",
    "    # direction: 0 for top to bottom, 1 for bottom to top\n",
    "\n",
    "    # Load the audio\n",
    "    audio = mp.AudioFileClip(audio_file)\n",
    "    \n",
    "    # Load the image\n",
    "    image_clip = mp.ImageClip(image_file).set_duration(audio.duration)  # Set the duration to match audio\n",
    "\n",
    "    audio = mp.AudioFileClip(audio_file).subclip(0, image_clip.duration)\n",
    "\n",
    "    # Resize the image to maintain a 16:9 aspect ratio (1920x1080) while preserving its aspect ratio\n",
    "    target_width = 12/9*1080 // 1\n",
    "    target_height = 1080\n",
    "    image_clip = image_clip.resize(height=target_width)  # Set height to 1920x1920\n",
    "\n",
    "    # Create a video clip with zooming and vertical panning effect\n",
    "    def make_frame(t):\n",
    "        if direction == 0:\n",
    "            # Pan from top to bottom\n",
    "            y_offset = (image_clip.h - target_height) * (t / audio.duration)  # Calculate vertical pan offset\n",
    "        else:\n",
    "            # Pan from bottom to top\n",
    "            y_offset = (image_clip.h - target_height) * (1 - t / audio.duration)\n",
    "\n",
    "        frame = image_clip.set_position(('center', 'top')).get_frame(t)\n",
    "        return frame[int(y_offset):int(y_offset + target_height), :, :]\n",
    "\n",
    "    # Create a video clip with the zoom and vertical panning effect\n",
    "    video_clip = mp.VideoClip(make_frame, duration=audio.duration)\n",
    "\n",
    "    # Set the audio for the video clip\n",
    "    video_clip = video_clip.set_audio(audio)\n",
    "\n",
    "    # Parse the subtitles manually\n",
    "    subtitles = parse_srt(subtitle_file)\n",
    "\n",
    "    # Create TextClip objects for each subtitle and overlay them\n",
    "    subtitle_clips = []\n",
    "    for start, end, text in subtitles:\n",
    "        # Use the specified custom font\n",
    "        txt_clip = TextClip(text, font='./datasets/simyou.ttf', fontsize=40, color='white')\n",
    "        txt_clip = txt_clip.set_position(('center', 'bottom')).set_start(start).set_duration(end - start)\n",
    "        subtitle_clips.append(txt_clip)\n",
    "\n",
    "    # Composite the video and subtitles\n",
    "    final_video = mp.CompositeVideoClip([video_clip] + subtitle_clips)\n",
    "\n",
    "    final_video = final_video.subclip(0, min(audio.duration, video_clip.duration)- 0.1)\n",
    "    \n",
    "    # Export the final video\n",
    "    final_video.write_videofile(output_file, fps=24, codec='libx264', audio_codec='aac', audio_bitrate='192k', preset='medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# image_file = \"datasets/yujie/scene_images/scene0.png\"  # Replace with the path to your PNG image\n",
    "# audio_file = \"datasets/yujie/yujie_n/yujie_tts_0/yujie_tts_0.mp3\"  # Replace with the path to your MP3 audio file\n",
    "# subtitle_file = \"datasets/yujie/yujie_n/yujie_tts_0/yujie_tts_0.srt\"  # Replace with the path to your SRT subtitle file\n",
    "# output_file = \"temp.mp4\"  # Replace with the desired output video file name\n",
    "\n",
    "# create_video_with_audio_and_subtitles(image_file, audio_file, subtitle_file, output_file, direction=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:14<00:07, 37.38it/s, now=None]\n",
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:14<00:07, 37.38it/s, now=None]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video datasets/yujie/videos/13.mp4.\n",
      "MoviePy - Writing audio in 13TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:14<00:07, 37.38it/s, now=None]\n",
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:14<00:07, 37.38it/s, now=None]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video datasets/yujie/videos/13.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:25<00:07, 37.38it/s, now=None]\n",
      "                                                                \n",
      "\n",
      "t:  71%|███████   | 648/919 [3:26:25<00:07, 37.38it/s, now=None]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready datasets/yujie/videos/13.mp4\n",
      "Created video datasets/yujie/videos/13.mp4\n",
      "All videos created successfully!\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import natsort\n",
    "import re\n",
    "import random\n",
    "\n",
    "all_mp3_folders = glob(\"datasets/yujie/yujie_n/*_tts_*/\")\n",
    "all_mp3_folders = natsort.natsorted(all_mp3_folders)\n",
    "\n",
    "output_folder = \"datasets/yujie/videos/\"\n",
    "\n",
    "for mp3_folder in all_mp3_folders:\n",
    "    \n",
    "    # index number\n",
    "    index = re.search(r'\\d+', mp3_folder).group()\n",
    "\n",
    "    if int(index) != 13:\n",
    "        continue\n",
    "    print(index)\n",
    "    # image file\n",
    "    image_file = f\"datasets/yujie/scene_images/scene{index}.png\"\n",
    "    # audio file\n",
    "    audio_file = f\"{mp3_folder}yujie_tts_{index}.mp3\"\n",
    "    # subtitle file\n",
    "    subtitle_file = f\"{mp3_folder}yujie_tts_{index}.srt\"\n",
    "\n",
    "    # output file\n",
    "    output_file = f\"{output_folder}{index}.mp4\"\n",
    "\n",
    "    direction = random.choice([0, 1])\n",
    "\n",
    "    create_video_with_audio_and_subtitles(image_file, audio_file, subtitle_file, output_file, direction=direction)\n",
    "    print(f\"Created video {output_file}\")\n",
    "    break\n",
    "\n",
    "print(\"All videos created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filelist.txt created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import natsort\n",
    "\n",
    "# Set the path to the folder containing videos\n",
    "video_folder = 'datasets/yujie/videos'  # or use '\\\\' for Windows paths\n",
    "\n",
    "# Get a list of all .mp4 files in the folder\n",
    "video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
    "\n",
    "# Sort the files in natural order\n",
    "sorted_videos = natsort.natsorted(video_files)\n",
    "\n",
    "# Create the filelist.txt file\n",
    "with open('datasets/yujie/filelist.txt', 'w') as filelist:\n",
    "    for video in sorted_videos:\n",
    "        filelist.write(f\"file '{os.path.join(video_folder, video)}'\\n\")\n",
    "\n",
    "print(\"filelist.txt created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
