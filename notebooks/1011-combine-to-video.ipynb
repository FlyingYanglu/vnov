{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heroe\\OneDrive\\桌面\\play-gpt\\vnov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heroe\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pil\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.tools.subtitles import SubtitlesClip, TextClip\n",
    "import os\n",
    "import re\n",
    "from moviepy.config import change_settings\n",
    "pil.ANTIALIAS = pil.Resampling.LANCZOS\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI\\\\magick.exe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_srt(srt_file, encoding=\"utf-8\"):\n",
    "    \"\"\"Parses the SRT file into a list of (start_time, end_time, subtitle_text) tuples.\"\"\"\n",
    "    pattern = re.compile(r\"(\\d{2}):(\\d{2}):(\\d{2}),(\\d{3})\")\n",
    "    subtitles = []\n",
    "\n",
    "    with open(srt_file, 'r', encoding=encoding) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current_sub = {}\n",
    "    for line in lines:\n",
    "        # Match time codes\n",
    "        if pattern.search(line):\n",
    "            times = pattern.findall(line)\n",
    "            start_time = int(times[0][0]) * 3600 + int(times[0][1]) * 60 + int(times[0][2]) + int(times[0][3]) / 1000\n",
    "            end_time = int(times[1][0]) * 3600 + int(times[1][1]) * 60 + int(times[1][2]) + int(times[1][3]) / 1000\n",
    "            current_sub['start'] = start_time\n",
    "            current_sub['end'] = end_time\n",
    "        elif line.strip() == '':\n",
    "            if 'text' in current_sub:\n",
    "                # Remove prefix numbers and keep only the subtitle text\n",
    "                text = re.sub(r'^\\d+\\s*', '', current_sub['text'].strip())\n",
    "                subtitles.append((current_sub['start'], current_sub['end'], text))\n",
    "            current_sub = {}\n",
    "        else:\n",
    "            if 'text' not in current_sub:\n",
    "                current_sub['text'] = line.strip()\n",
    "            else:\n",
    "                current_sub['text'] += ' ' + line.strip()\n",
    "    \n",
    "    return subtitles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_with_audio_and_subtitles(image_file, audio_file, subtitle_file, output_file):\n",
    "    # Load the audio\n",
    "    audio = mp.AudioFileClip(audio_file)\n",
    "    \n",
    "    # Load the image\n",
    "    image_clip = mp.ImageClip(image_file).set_duration(audio.duration)  # Set the duration to match audio\n",
    "\n",
    "    # Resize the image to maintain a 16:9 aspect ratio (1920x1080) while preserving its aspect ratio\n",
    "    target_width = 12/9*1080 // 1\n",
    "    target_height = 1080\n",
    "    image_clip = image_clip.resize(height=target_width)  # Set height to 1920x1920\n",
    "\n",
    "    # Create a video clip with zooming and vertical panning effect\n",
    "    def make_frame(t):\n",
    "        y_offset = (image_clip.h - target_height) * (t / audio.duration)  # Calculate vertical pan offset\n",
    "        frame = image_clip.set_position(('center', 'top')).get_frame(t)\n",
    "        return frame[int(y_offset):int(y_offset + target_height), :, :]\n",
    "    \n",
    "\n",
    "    # Create a video clip with the zoom and vertical panning effect\n",
    "    video_clip = mp.VideoClip(make_frame, duration=audio.duration)\n",
    "\n",
    "    # Set the audio for the video clip\n",
    "    video_clip = video_clip.set_audio(audio)\n",
    "\n",
    "    # Parse the subtitles manually\n",
    "    subtitles = parse_srt(subtitle_file)\n",
    "\n",
    "    # Create TextClip objects for each subtitle and overlay them\n",
    "    subtitle_clips = []\n",
    "    for start, end, text in subtitles:\n",
    "        # Use the specified custom font\n",
    "        txt_clip = TextClip(text, font='./datasets/simyou.ttf', fontsize=40, color='white')\n",
    "        txt_clip = txt_clip.set_position(('center', 'bottom')).set_start(start).set_duration(end - start)\n",
    "        subtitle_clips.append(txt_clip)\n",
    "\n",
    "    # Composite the video and subtitles\n",
    "    final_video = mp.CompositeVideoClip([video_clip] + subtitle_clips)\n",
    "    final_video = final_video.subclip(0, max(0, final_video.duration - 0.05))\n",
    "    \n",
    "    # Export the final video\n",
    "    final_video.write_videofile(output_file, fps=24, codec='libx264', audio_codec='aac', audio_bitrate='192k', preset='ultrafast')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 3/516 [07:40<21:53:29, 153.63s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./temp.mp4.\n",
      "MoviePy - Writing audio in tempTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 3/516 [07:41<21:55:23, 153.85s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./temp.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 3/516 [07:52<22:26:14, 157.46s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./temp.mp4\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "image_file = \"./datasets/yujie/scene_images/scene3.png\"  # Replace with the path to your PNG image\n",
    "audio_file = \"./datasets/yujie/yujie_n/yujie_tts_3/yujie_tts_3.mp3\"  # Replace with the path to your MP3 audio file\n",
    "subtitle_file = \"./datasets/yujie/yujie_n/yujie_tts_3/yujie_tts_3.srt\"  # Replace with the path to your SRT subtitle file\n",
    "output_file = \"./temp.mp4\"  # Replace with the desired output video file name\n",
    "\n",
    "create_video_with_audio_and_subtitles(image_file, audio_file, subtitle_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
